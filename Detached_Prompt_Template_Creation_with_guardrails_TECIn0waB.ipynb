{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1431ce28-77ce-443e-9b13-1ca914e8f40d"
   },
   "source": [
    "# Generative AI Model evaluation as a prompt template in watsonx.governance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9270bb81-2211-466c-b002-13a4a8d1e878"
   },
   "source": [
    "This notebook has been adapted for the watsonx.governance Level 4 PoX hands-on lab. It is originally based on [this notebook](https://github.com/rreno85/wxgovlab/blob/main/watsonxgov%20detached%20prompt%20-%20Azure%20OpenAI.ipynb) by Bob Reno.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11000d0d-a3da-463b-97b9-1f766cdac8bd"
   },
   "source": [
    "## Setup <a name=\"settingup\"></a>\n",
    "\n",
    "Run the below cell to install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f66daba2-fdbd-4d2f-89ae-0dead6f60bd1"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade datasets==2.10.0 --no-cache | tail -n 1\n",
    "!pip install --upgrade evaluate --no-cache | tail -n 1\n",
    "!pip install --upgrade --extra-index-url https://test.pypi.org/simple/ ibm-aigov-facts-client | tail -n 1\n",
    "!pip install --upgrade \"ibm-watson-openscale>=3.0.4\" | tail -n 1\n",
    "!pip install \"ibm-watson-machine-learning\"\n",
    "!pip install --upgrade matplotlib | tail -n 1\n",
    "!pip install --upgrade pydantic==1.10.11 --no-cache | tail -n 1\n",
    "!pip install --upgrade sacrebleu --no-cache | tail -n 1\n",
    "!pip install --upgrade sacremoses --no-cache | tail -n 1\n",
    "!pip install --upgrade textstat --no-cache | tail -n 1\n",
    "!pip install --upgrade openai rich azure-identity --no-cache | tail -n 1\n",
    "# !pip install --upgrade transformers --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5068ca17-4f03-42ed-a0fc-596e9a99eb10"
   },
   "source": [
    "**Note:** you may need to *restart the kernel* to use the updated packages. You don't need to run the cell above again after restarting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a147aac4-45ce-4b28-a96c-4f8cd7e62baa"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "903211bc-29b1-4488-8f54-7e000c0a1035"
   },
   "outputs": [],
   "source": [
    "### General ###\n",
    "import os\n",
    "from rich import print\n",
    "from IPython.display import display, Markdown\n",
    "import re\n",
    "import requests\n",
    "import urllib3, json  # noqa: E401\n",
    "urllib3.disable_warnings()\n",
    "import itc_utils.flight_service as itcfs\n",
    "\n",
    "### Factsheets ###\n",
    "from ibm_aigov_facts_client import (\n",
    "    AIGovFactsClient, CloudPakforDataConfig,\n",
    "    DetachedPromptTemplate, PromptTemplate\n",
    ")\n",
    "from ibm_aigov_facts_client.utils.enums import Task # used later\n",
    "\n",
    "### Openscale ###\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator, CloudPakForDataAuthenticator\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "from ibm_watson_openscale.base_classes import ApiRequestFailure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65a267dd-1a2b-4bc1-a8f9-ffe2c35c681d"
   },
   "source": [
    "### CPD & LLM Model Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65793428-ef4e-4299-9e22-49b4f75d8033"
   },
   "outputs": [],
   "source": [
    "CPD_URL = \"<Enter Cloud Pak for Data URL>\"\n",
    "CPD_USERNAME = \"<Enter Username>\"\n",
    "CPD_API_KEY = \"<Enter Key>\"\n",
    "\n",
    "PROJECT_ID = os.environ.get('PROJECT_ID', \"<YOUR_PROJECT_ID>\")\n",
    "print(f\"Your project id is '{PROJECT_ID}'\")\n",
    "\n",
    "MODEL_ENDPOINT = \"<Enter Model Endpoint>\"\n",
    "MODEL_CLIENT_ID = \"<Enter Model Client ID>\"\n",
    "MODEL_CLIENT_SECRET = \"<Enter Model Client Secret>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2a42eb8-5db3-414c-a1c4-16f97dd50e95"
   },
   "source": [
    "### Function to create the model access token for LLM\n",
    "\n",
    "This function generates an bearer access token using the provided credentials. The API calls for creating and scoring prompt template assets utilize the token generated by this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a72f5e58-d04b-4944-a04c-f68597a4d987"
   },
   "outputs": [],
   "source": [
    "def get_bearer_token(env: str, client_id: str, client_secret: str) -> str:\n",
    "    if env == \"PROD\":\n",
    "        auth_url=\"https://mie.kinesso.com/api/token\"\n",
    "    else:\n",
    "        auth_url=f'https://{env}-mie.kinesso.com/api/token'\n",
    "\n",
    "    data = {'grant_type': 'client_credentials'}\n",
    "\n",
    "    response = requests.post(auth_url, data=data, auth=(client_id, client_secret))\n",
    "\n",
    "    if not response.ok:\n",
    "        raise Exception(f\"Failed to get bearer token: {response.text}\")\n",
    "\n",
    "    return response.json().get('access_token')\n",
    "\n",
    "bearer_token = get_bearer_token(\"DEV\", MODEL_CLIENT_ID, MODEL_CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87b5ca18-5627-42dd-9b38-ad3eb4a206aa"
   },
   "source": [
    "### Function to ask the LLM agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e1bac7b1-3924-4b7d-94b4-1593dacdd75a"
   },
   "outputs": [],
   "source": [
    "def ask_agent(endpoint, bearer_token, question):\n",
    "    bearer = bearer_token\n",
    "\n",
    "    url = endpoint\n",
    "\n",
    "    json_data = {\n",
    "        'message': question,\n",
    "    }\n",
    "    print(f'approx tokens used: {len(question)//4}')\n",
    "\n",
    "    headers = {\n",
    "        # 'accept': 'application/json, text/plain, */*',\n",
    "        'authorization': f'Bearer {bearer}',\n",
    "        'content-type': 'application/json',\n",
    "    }\n",
    "\n",
    "    r1 = requests.post(url,  headers=headers, json=json_data)\n",
    "    return r1.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "149f387e-9850-4f12-816c-247cc6ac0c83"
   },
   "source": [
    "## Creating the Prompt Template\n",
    "\n",
    "The following cell shows the development of a prompt template used to generate content from IPG model. \n",
    "\n",
    "We will test inference on Watsonx Evaluation and create a detached prompt template in our project in watsonx that references the model and prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "28147783-ef9a-4f92-9d7f-93e9c7545f9b"
   },
   "outputs": [],
   "source": [
    "#Given the following 10 user inputs, generate an outline in the format of the Content Type. Use the other inputs to determine the content of the outline.\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Given the following 10 user inputs, generate a brief article of media content in the format of the Content Type. Use the other inputs to determine the content. Some inputs may be blank; you can ignore them. Adhere to the following guidelines while generating the content:\n",
    "\n",
    "1. **Factual Accuracy**: Ensure all information is truthful, fact-checked, and avoids making unsupported claims.\n",
    "2. **Avoid Deceptive Practices**: Do not include misleading statements, exaggerated claims, or false advertising.\n",
    "3. **Content Moderation**: Avoid offensive, hateful, abusive, or profane language, and ensure the content is appropriate for the specified Target Audience.\n",
    "4. **Protect PII and Privacy**: Do not include sensitive or personally identifiable information (PII) or encourage unethical data collection practices.\n",
    "5. **Professionalism and Brand Alignment**: Ensure the tone, language, and content align with the professionalism and reputation of the brand or industry specified.\n",
    "6. **Inclusive and Ethical Messaging**: Avoid stereotyping or exclusionary language, and ensure the content respects diverse audiences and cultural sensitivities.\n",
    "7. **Value-Driven Content**: Focus on providing value to the Target Audience, such as education, inspiration, or solving a problem, rather than solely promotional messaging.\n",
    "8. **Compliance**: Ensure the content complies with relevant marketing regulations, such as GDPR, FTC guidelines, or industry-specific advertising standards.\n",
    "9. **SEO Best Practices**: Appropriately incorporate the Primary Keywords into the content naturally and without keyword stuffing.\n",
    "10. **Call-to-Action (CTA)**: If applicable, include a clear and ethical CTA aligned with the Objective without being overly aggressive or pushy.\n",
    "\n",
    "User inputs:\n",
    "Content Type: {content_type}\n",
    "Product Description: {product_description}\n",
    "Location: {location}\n",
    "Industry: {industry}\n",
    "Target Audience: {target_audience}\n",
    "Audience Stage of Awareness: {audience_stage_of_awareness}\n",
    "Objective: {objective}\n",
    "Primary Keywords: {primary_keywords}\n",
    "Tone: {tone}\n",
    "Number of Words: {number_of_words}\n",
    "\"\"\".strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de9f4870-e1fb-45da-8dd6-6f8d12399009"
   },
   "source": [
    "### Create the detached prompt template <a name=\"detached_prompt\"></a>\n",
    "\n",
    "Create a detached prompt template in your project for the generation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "69f88bdc-efb8-4236-bfb1-9a4cdde4bbb0"
   },
   "outputs": [],
   "source": [
    "creds = CloudPakforDataConfig(\n",
    "    service_url=CPD_URL,\n",
    "    username=CPD_USERNAME,\n",
    "    api_key=CPD_API_KEY\n",
    ")\n",
    "\n",
    "# Create a factsheet client\n",
    "\n",
    "facts_client = AIGovFactsClient(\n",
    "    cloud_pak_for_data_configs=creds,\n",
    "    container_id=PROJECT_ID,\n",
    "    container_type=\"project\",\n",
    "    disable_tracing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "324b7daa-653a-469b-aeb6-b1f0d2c60302"
   },
   "outputs": [],
   "source": [
    "detached_information = DetachedPromptTemplate(\n",
    "    prompt_id=\"ibm_dev_brandvoice\",\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    model_provider=\"Anthropic\",\n",
    "    model_name=\"Claude 3.5 Sonnet\",\n",
    "    model_url=MODEL_ENDPOINT,\n",
    "    prompt_url=\"prompt_url\",\n",
    "    prompt_additional_info={\"model_owner\": \"IPG\", \"model_version\": \"v1.0\"}\n",
    ")\n",
    "prompt_name = \"Detached prompt for Brand Voice LLM - WITH GUARDRAILS\"\n",
    "prompt_description = \"A detached prompt for content generation using Anthropic Claude's 3.5 Sonnet model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dd414ad5-47cf-4dcb-b807-827983c994cb"
   },
   "outputs": [],
   "source": [
    "# add guardrails and compare with original prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f647aac-d980-4b9f-a635-447e46491f4b"
   },
   "outputs": [],
   "source": [
    "# define parameters for PromptTemplate\n",
    "prompt_template = PromptTemplate(\n",
    "    input=PROMPT_TEMPLATE,\n",
    "    prompt_variables={\"input\": \"\"\n",
    "                     }\n",
    ")\n",
    "pta_details = facts_client.assets.create_detached_prompt(\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    task_id=Task.GENERATION, # 'generation' task\n",
    "    name=prompt_name,\n",
    "    description=prompt_description,\n",
    "    prompt_details=prompt_template,\n",
    "    detached_information=detached_information\n",
    ")\n",
    "project_pta_id = pta_details.to_dict()[\"asset_id\"]\n",
    "print(f\"Detached Prompt template ID: '{project_pta_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd87f51d-301c-476c-b93b-fc99b805bcaf"
   },
   "outputs": [],
   "source": [
    "factsheets_url = f\"{CPD_URL.strip('/')}/wx/prompt-details/{project_pta_id}/factsheet?context=wx&project_id={PROJECT_ID}\"\n",
    "display(Markdown(f\"[Click here to navigate to the published factsheet in the project]({factsheets_url})\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc570d87-62d0-46e3-9932-e916a966bef3"
   },
   "source": [
    "# Configure & Setup OpenScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56611d45-9d4b-4e19-8263-dc8f9427f425"
   },
   "outputs": [],
   "source": [
    "authenticator = CloudPakForDataAuthenticator(\n",
    "    url=CPD_URL,\n",
    "    username=CPD_USERNAME,\n",
    "    apikey=CPD_API_KEY,\n",
    "    disable_ssl_verification=False\n",
    ")\n",
    "wos_client = APIClient(\n",
    "    service_url=CPD_URL,\n",
    "    authenticator=authenticator,\n",
    "    service_instance_id=None\n",
    ")\n",
    "data_mart_id = wos_client.service_instance_id\n",
    "# print(data_mart_id)\n",
    "print(wos_client.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3b175d63-4fe7-434c-af02-6defad754383"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  wos_client.wos.add_instance_mapping(                \n",
    "    service_instance_id=data_mart_id,\n",
    "    project_id=PROJECT_ID\n",
    "  )\n",
    "except ApiRequestFailure as arf:\n",
    "   if arf.response.status_code == 409:\n",
    "      # Instance mapping already exists. Ignore the error and continue\n",
    "      pass\n",
    "   else:\n",
    "      raise arf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a2da5c5-7397-4eda-9346-b9f81585d33e"
   },
   "source": [
    "### Evaluation Metrics, Structure Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "673f9a41-4a44-44a3-b20f-e36901d63b21"
   },
   "outputs": [],
   "source": [
    "label_column = \"output_expected\"\n",
    "operational_space_id = \"development\"\n",
    "problem_type = \"generation\"\n",
    "input_data_type = \"unstructured_text\"\n",
    "\n",
    "monitors = {\n",
    "    \"generative_ai_quality\": {\n",
    "          \"thresholds\": [\n",
    "            {\n",
    "              \"metric_id\": \"rouge1\",\n",
    "              \"type\": \"lower_limit\",\n",
    "              \"value\": 0.8\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"rouge2\",\n",
    "              \"type\": \"lower_limit\",\n",
    "              \"value\": 0.8\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"rougel\",\n",
    "              \"type\": \"lower_limit\",\n",
    "              \"value\": 0.8\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"rougelsum\",\n",
    "              \"type\": \"lower_limit\",\n",
    "              \"value\": 0.8\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"normalized_f1\",\n",
    "              \"type\": \"lower_limit\",\n",
    "              \"value\": 0.8\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"normalized_precision\",\n",
    "              \"type\": \"lower_limit\",\n",
    "              \"value\": 0.8\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"normalized_recall\",\n",
    "              \"type\": \"lower_limit\",\n",
    "              \"value\": 0.8\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"pii\",\n",
    "              \"type\": \"upper_limit\",\n",
    "              \"value\": 0\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"hap_score\",\n",
    "              \"type\": \"upper_limit\",\n",
    "              \"value\": 0\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"pii_input\",\n",
    "              \"type\": \"upper_limit\",\n",
    "              \"value\": 0\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"hap_input_score\",\n",
    "              \"type\": \"upper_limit\",\n",
    "              \"value\": 0\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"meteor\",\n",
    "              \"type\": \"lower_limit\",\n",
    "              \"value\": 0.8\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"bleu\",\n",
    "              \"type\": \"lower_limit\",\n",
    "              \"value\": 0.8\n",
    "            },\n",
    "            {\n",
    "              \"metric_id\": \"flesch_reading_ease\",\n",
    "              \"type\": \"lower_limit\",\n",
    "              \"value\": 60\n",
    "            }\n",
    "          ],\n",
    "          \"parameters\": {\n",
    "            \"metrics_configuration\": {\n",
    "              \"pii\": {\n",
    "                \"record_level_max_score\": 0.5\n",
    "              },\n",
    "              \"hap_score\": {\n",
    "                \"record_level_max_score\": 0.5\n",
    "              },\n",
    "              \"pii_input\": {\n",
    "                \"record_level_max_score\": 0.5\n",
    "              },\n",
    "              \"hap_input_score\": {\n",
    "                \"record_level_max_score\": 0.5\n",
    "              },\n",
    "              \"bleu\": {\n",
    "                \"max_order\": 4,\n",
    "                \"smooth\": False\n",
    "              },\n",
    "              \"flesch\": {},\n",
    "              \"meteor\": {\n",
    "                \"alpha\": 0.9,\n",
    "                \"beta\": 3,\n",
    "                \"gamma\": 0.5\n",
    "              },\n",
    "              \"normalized_recall\": {},\n",
    "              \"normalized_f1\": {},\n",
    "              \"rouge_score\": {\n",
    "                \"use_aggregator\": True,\n",
    "                \"use_stemmer\": False\n",
    "              },\n",
    "              \"normalized_precision\": {}\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "}\n",
    "\n",
    "response = wos_client.wos.execute_prompt_setup(\n",
    "    prompt_template_asset_id=project_pta_id, \n",
    "    project_id=PROJECT_ID,\n",
    "    label_column=label_column,\n",
    "    operational_space_id=operational_space_id, \n",
    "    problem_type=problem_type,\n",
    "    input_data_type=input_data_type, \n",
    "    supporting_monitors=monitors, \n",
    "    background_mode=False\n",
    ")\n",
    "result = response.result\n",
    "result.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3ae13f7-f7e6-4098-a0a3-028359cd687c"
   },
   "outputs": [],
   "source": [
    "response = wos_client.wos.get_prompt_setup( # wos_client.monitor_instances.mrm.get_prompt_setup # if using an older version of facts client\n",
    "    prompt_template_asset_id=project_pta_id,\n",
    "    project_id=PROJECT_ID\n",
    ")\n",
    "\n",
    "result = response.result\n",
    "result_json = result.to_dict()\n",
    "\n",
    "if result_json[\"status\"][\"state\"] == \"FINISHED\":\n",
    "    print(\"Finished prompt setup. The response is {}\".format(result_json))\n",
    "else:\n",
    "    print(\"Prompt setup failed. The response is {}\".format(result_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9b5ac6e6-a74e-45ab-97b1-f4ee6e88138c"
   },
   "outputs": [],
   "source": [
    "subscription_id = result_json[\"subscription_id\"]\n",
    "mrm_monitor_instance_id = result_json[\"mrm_monitor_instance_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1b36be46-fc50-40dd-b8f5-9c87e1c0894d"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show(target_target_id=subscription_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94c41958-7be8-4fcc-90c4-2b9bb60010eb"
   },
   "outputs": [],
   "source": [
    "nb_data_request = {\n",
    "    'data_name': \"\"\"ipg_llms_input_outputs (1).csv\"\"\",\n",
    "    'interaction_properties': {\n",
    "        #'row_limit': 500,\n",
    "        'infer_schema': 'true',\n",
    "        'infer_as_varchar': 'false'\n",
    "    }\n",
    "}\n",
    "flight_descriptor = itcfs.get_flight_descriptor(nb_data_request=nb_data_request)\n",
    "\n",
    "flightClient = itcfs.get_flight_client()\n",
    "flightInfo = flightClient.get_flight_info(flight_descriptor)\n",
    "\n",
    "data = itcfs.read_pandas_and_concat(flightClient, flightInfo, timeout=240)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50ff587c-f654-47ef-8073-46afe57a5a25"
   },
   "source": [
    "### Looking at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5dc9f64c-29ef-457c-a002-222e3b8fdcd0"
   },
   "outputs": [],
   "source": [
    "data = data.loc[0:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "b0316882-cb97-4450-8e92-902ee52027cd"
   },
   "outputs": [],
   "source": [
    "llm_data = data.iloc[:,:2].copy()\n",
    "#llm_data = llm_data[['Resume', 'Summarization', 'generated_text']].rename(columns={\"Resume\":\"text\", 'Summarization': 'reference_summary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34c60964-7dc8-474f-8fdc-52a0d2beec58",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22232204-8f5c-44d6-b116-80ea9d42e097"
   },
   "outputs": [],
   "source": [
    "print(llm_data['input'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd20ea5a-41b2-4b53-9721-c0ae69270b64"
   },
   "source": [
    "### Function to extract parameters from a single prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "03c309eb-9c4c-418a-8a94-c74beebf0ee2"
   },
   "outputs": [],
   "source": [
    "def extract_parameters(parameter_string):\n",
    "    param_dict = {\n",
    "        \"product_description\": \"\",\n",
    "        \"location\": \"\",\n",
    "        \"industry\": \"\",\n",
    "        \"target_audience\": \"\",\n",
    "        \"audience_stage_of_awareness\": \"\",\n",
    "        \"objective\": \"\",\n",
    "        \"primary_keywords\": \"\",\n",
    "        \"tone\": \"\",\n",
    "        \"content_type\": \"\",\n",
    "        \"number_of_words\": \"\"\n",
    "    }\n",
    "    \n",
    "    for param in param_dict.keys():\n",
    "        pattern = param.replace(\"_\", \" \").title()\n",
    "        match = re.search(f\"{pattern}: (.*)\", parameter_string)\n",
    "        if match:\n",
    "            param_dict[param] = match.group(1).strip()\n",
    "    \n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6952c60-7d81-40fd-b34d-ccc628ef7318"
   },
   "source": [
    "### Function to generate and save LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "36eccc29-5f8c-43d3-94b2-af63fdb25ab9"
   },
   "outputs": [],
   "source": [
    "def get_llm_output(row):\n",
    "    \"\"\"\n",
    "    Gets the response from the LLM for the current row's prompt, taken from the column 'input'\n",
    "    \"\"\"\n",
    "    parameters_dict = extract_parameters(row['input'])\n",
    "    llm_input = PROMPT_TEMPLATE.format(**parameters_dict)\n",
    "    \n",
    "    responsejson = ask_agent(\n",
    "    MODEL_ENDPOINT, \n",
    "    bearer_token, \n",
    "    llm_input #+ \"\"\" No need to send us an outline for review, straight up generate a content.\"\"\"\n",
    "    )\n",
    "\n",
    "    for key in parameters_dict.keys():\n",
    "        row[key] = parameters_dict[key]\n",
    "        \n",
    "    row['generated_text'] = responsejson['message']\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a1f3fcb-e039-49cc-bba6-80223398ed6e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm_data = llm_data.apply(get_llm_output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32836fbc-f155-4218-8c71-94485ed4d21f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(llm_data['generated_text'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "49e7b3fa-a4a9-44aa-bd6c-ffe1f246c8c6"
   },
   "outputs": [],
   "source": [
    "llm_data[['input', 'output_expected', 'generated_text']].to_csv(\"test_data.csv\", index=False)\n",
    "# llm_data.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5b6d3135-7bad-43aa-833b-0095474f4359"
   },
   "outputs": [],
   "source": [
    "test_data_set_name = \"data\"\n",
    "test_data_path = \"\"\"test_data.csv\"\"\"\n",
    "content_type = \"multipart/form-data\"\n",
    "body = {}\n",
    "response  = wos_client.monitor_instances.mrm.evaluate_risk(\n",
    "    monitor_instance_id=mrm_monitor_instance_id,\n",
    "    test_data_set_name=test_data_set_name, \n",
    "    test_data_path=test_data_path,\n",
    "    content_type=content_type,\n",
    "    body=body,\n",
    "    project_id=PROJECT_ID,\n",
    "    includes_model_output=True,\n",
    "    background_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ea86caf-347c-4dad-89c7-de97b096834d"
   },
   "outputs": [],
   "source": [
    "response  = wos_client.monitor_instances.mrm.get_risk_evaluation(mrm_monitor_instance_id, project_id=PROJECT_ID)\n",
    "response.result.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23af31c0-cce0-4318-a41c-0e5071d50835"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=mrm_monitor_instance_id, project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "249c2042-a796-4a38-9c8e-e291bcc5f760"
   },
   "source": [
    "## Retrieving  Gen AI Quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14d5e8f6-3846-475f-b62b-8674e3eeb4dc"
   },
   "outputs": [],
   "source": [
    "# Get the ID of the generative AI quality monitor\n",
    "monitor_definition_id = \"generative_ai_quality\"\n",
    "result = wos_client.monitor_instances.list(\n",
    "    data_mart_id=data_mart_id,\n",
    "    monitor_definition_id=monitor_definition_id,\n",
    "    target_target_id=subscription_id,\n",
    "    project_id=PROJECT_ID\n",
    ").result\n",
    "result_json = result._to_dict()\n",
    "genaiquality_monitor_id = result_json[\"monitor_instances\"][0][\"metadata\"][\"id\"]\n",
    "genaiquality_monitor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34da68cd-bc00-4e5d-837e-00787a314e52"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=genaiquality_monitor_id, project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0adb931-f80f-4234-8e14-4d73eba76e88"
   },
   "source": [
    "## Record (Test Data Row) level metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f80ec02-c54e-419b-85fb-31bb89860209"
   },
   "outputs": [],
   "source": [
    "result = wos_client.data_sets.list(\n",
    "    target_target_id=subscription_id,\n",
    "    target_target_type=\"subscription\",\n",
    "    type=\"gen_ai_quality_metrics\"\n",
    ").result\n",
    "\n",
    "genaiq_dataset_id = result.data_sets[0].metadata.id\n",
    "genaiq_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e423935b-8995-457d-ac90-2e03f8923296"
   },
   "outputs": [],
   "source": [
    "wos_client.data_sets.show_records(data_set_id=genaiq_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f81605c5-c920-4de1-b29e-fcb770797c7b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
